<!DOCTYPE html>
<html>
  <head>
    <title>Causal Inference for Data Science</title>
    <meta charset="utf-8">
    <meta name="author" content="Mathew Kiang, Zhe Zhang, Monica Alexander" />
    <meta name="date" content="2017-03-15" />
    <link rel="stylesheet" href="custom.css" type="text/css" />
    <link rel="stylesheet" href="../custom.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Causal Inference for Data Science
## ITAM Short Workshop
### Mathew Kiang, Zhe Zhang, Monica Alexander
### March 15, 2017

---

name: inverse
layout: true
class: center, middle, inverse



---

# Statistics of Causal Inference

- causal interpretation of linear regression
- possible causal biases / "mis-identification"
- linear regression is not restrictive

???
Linear regression is interpretable. We care about unbiased interpretations rather than predictive fit. These overlap, but the former is most important.

---
# Example Data

![CEF_example](./assets/mhe_cef.png)
??
In this example, we have years of education on the x-axis and wage earnings on the y-axis.
The grey areas represent the distribution of data from each person with that wage.
We're clearly not going to try to explain such a variable thing. 
Instead, we start with the simple idea that there is clear causal pattern due to years of education.

---

# Review of Linear Regression

- (continuous) outcome is additive in the features
`$$Y_i = \beta_0 + \beta \mathbf{X_i} + \epsilon_i$$`
--
`$$Y_i = \beta_0 + \gamma T_i + \beta \mathbf{X_i} + \epsilon_i$$`

- not limited to simple linear possibilities (interactions, feature transformation, semi-parametric methods)

??
- Going to spend a lot of time thinking about `\(\gamma\)` and `\(\epsilon_i\)`.
- Though we will just use regression, this does not limit our scope much:

---
# Causal Linear Regression

- What we really care about:
$$ E[Y|X=x_i] $$

![CEF_regression](./assets/mhe_cef_regression.png)

---
# Recreate Graphic


```r
library(tidyverse); library(haven)
df &lt;- read_dta('../datasets/ak_91_iv_qob.dta')
year_df &lt;- df %&gt;%
  group_by(s) %&gt;%
  summarise(mean_lw = mean(lnw))
ggplot(year_df, aes(x = s, y = mean_lw)) + geom_point() +
  geom_line()
```

![](lec_3_linreg_and_biases_files/figure-html/unnamed-chunk-1-1.png)&lt;!-- --&gt;


---

# Causal Regression

- conditional expectation function (CEF) is argued to be causal
- controlling for observed differences
- estimating systematic randomness; 
  - we know we can't explain (close to) everything
  - instead, we want *unbiased* estimates of particular causal patterns

??
We know that it's not that simple to explain complex real-world outcomes with a linear model.
However, if we believe we have an unbiased estimate, this is helpful approximation. The exact numbers usually aren't that crucial.
And linear models are fairly robust.

---

# Regression Maths

- True CEF (best estimate for `\(Y_i\)`): `$$Y_i = E[Y_i|X=X_i]+\epsilon_i$$`
- Linear regression estimates the best MSE **linear** approximation for `\(E[Y_i|X_i]\)`
  - how does the distribution of `\(Y_i\)` change *wrt* `\(X_i\)`?
  - linear regression gives us interpretable coefficients
- Only the average causal effect
  
---

# Regression Maths (in Potential Outcomes)

- [todo] copy from MKiang?

---

# Note on Causal Language

- be careful using: {"effect", "leads to", "results in", "because of"}
- instead when just observed patterns {"related with", "pattern", "correlation", "tends to", "observed"}

---

# Conditional Independence ("controls")

- getting a Master's degree may not be appropriately random
- people who are prescribed a drug treatment may not be comparable to general population

- it could be argued though:
  - students with similar GPA, age, and Bachelor degrees may be random
  - people with similar blood measurements seen by different doctors may have random drug treatment
  
- `\({Y_{0i}, Y_{1i}} \bot C_i ?\)`

--

- `\({Y_{0i}, Y_{1i}} \bot C_i | \mathbf{X_i}?\)`
- `\(Y_{si} \bot s_i | \mathbf{X_i}\quad\forall s?\)`

---

# Avg Causal Effect

$$
\begin{align*}
\ &amp; E[Y_{i}|X_{i},s_{i}=s]-E[Y_{i}|X_{i},s_{i}=s-1]\\
 &amp; =E[Y_{si}-Y_{(s-1)i}|X_{i}]
\end{align*}
$$

--
- but there's an `\(X_i\)` there?

# Linear Regression with CIA

- linear additive assumption simplifies things

$$
\begin{align*}
\ \gamma_{s_i} &amp; =E[Y_{i}|X_{i},s_{i}=s]-E[Y_{i}|X_{i},s_{i}=s-1]\\
 &amp; =E[Y_{si}-Y_{(s-1)i}] + \beta X_i - \beta X_i\\
 &amp; =E[Y_{si}-Y_{(s-1)i}]
\end{align*}
$$

---

# Possibles Biases (many!)

observational data

(almost) All data is observational.

If you think you have an experiment, it's probably still observational data.

- omitted variable bias
- selection bias
- regression form bias

??
OVB and selection bias are similar

---
# Omitted Variable Bias

when Conditional Independece is violated

- omitted variables = (uncontrolled) correlation with the `\(T_i\)` 
- leads the error term `\(\epsilon_i\)` to affect estimate of `\(\gamma\)`
- **confounding**

???
- most common occurrence in analysis, i.e. OVB
- up to analyst to decide if OVB affects insights
- occurs when omitted variable affects both the outcome and a predictor

---
# OVB Illustrated

[todo] replace this

![illustrated_confound](./assets/iv_confound.png)

---
# OVB Examples

![ovb_education](./assets/ovb_estimates.png)

---
# OVB Examples


```r
library(tidyverse)
df_educ &lt;- data_frame(iq = runif(200, 1, 100),
                      school_years = 16 - 0.05*iq + rnorm(200),
                      income = 20000 + 5000*school_years + 5000*rnorm(200) + 500*iq)
summary(lm(income ~ school_years, data = df_educ))
```

```
## 
## Call:
## lm(formula = income ~ school_years, data = df_educ)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -23893.0  -7727.0   -430.4   5994.1  28691.1 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  133934.1     5679.2  23.583  &lt; 2e-16 ***
## school_years  -1644.5      417.3  -3.941 0.000113 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 10240 on 198 degrees of freedom
## Multiple R-squared:  0.07272,	Adjusted R-squared:  0.06804 
## F-statistic: 15.53 on 1 and 198 DF,  p-value: 0.0001126
```

```r
summary(lm(income ~ school_years + iq, data = df_educ))
```

```
## 
## Call:
## lm(formula = income ~ school_years + iq, data = df_educ)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -15303.1  -3013.2    549.6   3373.5  12160.9 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  15298.22    5710.16   2.679  0.00801 ** 
## school_years  5166.64     353.29  14.624  &lt; 2e-16 ***
## iq             541.69      22.54  24.036  &lt; 2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 5176 on 197 degrees of freedom
## Multiple R-squared:  0.7642,	Adjusted R-squared:  0.7618 
## F-statistic: 319.2 on 2 and 197 DF,  p-value: &lt; 2.2e-16
```


---
# What does it mean to "control for covariates"?

- makes observed outcomes independent of our causal treatment/action of interest
- based on theory only though; there can always be omitted variable bias
  - and bias caused by bad controls
  - and functional form biases

---
# Omitted Variables

- we rarely "prove" causality
- instead, we argue based on domain expertise and theory that we are not facing biases
- often, a good analysis adjusts a lot of the assumptions to ensure the results are "robust" to possible biases


---
# OVB Thought Examples

what observational data is available?

- effect of air quality policy
- effect of advertising campaign
- effect of OTC drug campaign
- effect of customer loyalty campaign
- adoption of a mobile app
- calling customer service


---
# Selection Bias

(usually, this falls under omitted variable bias)

- sometimes selection bias can be also important for external validity
- "average" causal effect may be poorly estimated 

---
# Regression Functional Form Bias

- non-linear outcome variables
  - wages is usually not linear in the outcomes
    - we usually use `\(\log (wage)\)` instead!
    - `\(\log(wage) ~ \beta educ\)`, now `\(\beta\)` is interpreted as a percent increase in wage
- sometimes our features are non-linear too `\(\beta_i age + \beta_j age^2\)`
- 0/1 outcome variable?
  - logistic regression is common
  - Probit regression has a more economic interpretation, based on an individual's response to 
  - Poisson regression for counts
- Truncated/Censored Observation (e.g., test scores, wage)
- Attrition bias

- *important to think critically about where the (potential) data comes from or would come from*
- *almost all interesting data comes from human decisions, which is complex and may have several things affecting it*

---
# Extensions to Linear Form

- interactions: `\(\beta_j X_j \cdot X_k\)`
- feature transformations: `\(log(Y_i)\)`
- flexible semi-parametric: $Y_i = \beta_0 + \gamma T_i + \beta f(\mathbf{X_i}) + \epsilon_i $

---
# Despite Caution, Causal Work Still Useful

- Raj Chetty, policy impact
- Work on piracy affecting movie studios
- Health insurance

---
# Sources

- Cameron &amp; Triveti textbook
- Mostly Harmless Econometrics
- Osea Giuntella, slides
    </textarea>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('showSlide', function (slide) {setTimeout(function() {window.dispatchEvent(new Event('resize'));}, 100)});</script>

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
  }
});
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
