<!DOCTYPE html>
<html>
  <head>
    <title>Causal Inference for Data Science</title>
    <meta charset="utf-8">
    <meta name="author" content="Mathew Kiang, Zhe Zhang, Monica Alexander" />
    <meta name="date" content="2017-03-15" />
    <link rel="stylesheet" href="custom.css" type="text/css" />
    <link rel="stylesheet" href="../custom.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Causal Inference for Data Science
## ITAM Short Workshop
### Mathew Kiang, Zhe Zhang, Monica Alexander
### March 15, 2017

---

name: inverse
layout: true
class: center, middle, inverse




---
# Reminder: Omitted Variables

- we rarely "prove" causality
- instead, we argue based on domain expertise and theory that we are not facing biases
- often, a good analysis adjusts a lot of the assumptions to ensure the results are "robust" to possible biases

---
# Reminder: Control Variables To Get CIA

- Conditional Independance Assumption 
- "outcomes are random with respect to Treatment, once we adjust for certain covariates"

We can't always get this argument to be believable though.

??
Some things are quite hard to measure, such as genetic influence, choices for why people move to particular neighborhoods, IQ, motivation, involvement in other related activities

Ultimately, we're often left with omitted variable bias.

---
# Instrumental Variables

- variables in the world or data that helps to encourage a real-world experiment
- by leveraging this information, we can remove omitted variable bias
- denote such instruments with `\(z_i\)` variables for each observation `\(i\)`

--
- Different from a control variable. Does not enable conditional independence assumption (CIA).

---
# Instrumental Variables Graphically

- replace with our own graphics for consistent letters

![iv_base](./assets/iv_no_issue.png) ![iv_base](./assets/iv_confound.png)
![iv_base](./assets/iv_with_z.png)

---
# Instrumental Variable Key

- cannot use the observed `\(T_i\)`, which we believe is influenced by unobserved confounders
- observed variation in `\(T_i\)` = "random/natural" variation + systematic variation from unobservables

- do we have something that can predict only the "random" variation in `\(T_i\)`?
- Get `\(\hat{T_i} = f(Z_i, X_i)\)` where `\(\hat{T_i} \bot u_i\)`. So `\(\hat{T_i}\)` is only influenced by `\(Z_i\)`.

---
# Exclusion Restriction

`\(Z_i\)` only works if it does NOT look like `\(U_i\)`.

- `\(Z_i\)` must be essentially randomly assigned, conditional on other covariates `\(X_i\)`
- it cannot influence the outcome `\(Y_i\)` except through `\(T_i\)`

???
We're not looking at the math here, but we trust that if you get the idea, you can look up a textbook or an online source to clarify the math for why this works.

---
# Key Instrumental Variable Checks

- Relevance condition / weak instrument?

- "Exclusion restriction"
--
  - *impossible to check!*

---
# How to Use an Instrumental Variable

1. Get `\(\hat{T_i}\)` predicted on the instrument + other covariates. ("First Stage")
  - usually, look at `\(R^2\)` or special type of F-test
  
2. Use the regression `\(Y_i = \gamma \hat{T_i}|_{(Z_i,X_i)} + \beta X_i + \epsilon_i\)` ("Second Stage")

---
# Example: Birthdate as an IV

Angrist, Kreuger 1991; study of school on future earnings

--

```r
library(tidyverse); library(stringr); library(haven)
```

```
## Loading tidyverse: ggplot2
## Loading tidyverse: tibble
## Loading tidyverse: tidyr
## Loading tidyverse: readr
## Loading tidyverse: purrr
## Loading tidyverse: dplyr
```

```
## Conflicts with tidy packages ----------------------------------------------
```

```
## filter(): dplyr, stats
## lag():    dplyr, stats
```

```r
df &lt;- read_dta('./../datasets/ak_91_iv_qob.dta')
agg_df &lt;- df %&gt;% unite(yob_qob, yob, qob, remove = F) %&gt;%
  group_by(yob_qob) %&gt;%
  summarise(mean_s = mean(s),
            qob = mean(qob),
            yob = mean(yob),
            mean_lnw = mean(lnw))
ggplot(agg_df, aes(x = yob_qob, y = mean_s, group = NA)) + 
  geom_point(aes(color = factor(qob)), size = 3) + 
  geom_line() + geom_label(aes(label = qob,
                               fill = factor(qob))) +
  scale_x_discrete(breaks = agg_df$yob_qob[str_detect(agg_df$yob_qob, "_1")])
```

![](lec_4_instrumental_variables_files/figure-html/unnamed-chunk-1-1.png)&lt;!-- --&gt;

---
# Loose Check for Relevance


```r
ggplot(agg_df, aes(x = yob_qob, y = mean_lnw, group = NA)) + 
  geom_point(aes(color = factor(qob)), size = 3) + 
  geom_line() + geom_label(aes(label = qob, 
                               fill = factor(qob))) +
  scale_x_discrete(breaks = agg_df$yob_qob[str_detect(agg_df$yob_qob, "_1")])
```

![](lec_4_instrumental_variables_files/figure-html/unnamed-chunk-2-1.png)&lt;!-- --&gt;

---
# Try 2SLS By Hand


```r
library(tidyverse)
df &lt;- read_dta('../datasets/ak_91_iv_qob.dta') %&gt;%
  mutate_at(.funs = as.factor, .cols = c("yob", "sob", "qob")) %&gt;%
  mutate(q4 = ifelse(qob == 4, 1, 0))
# check first stage
no_instrument &lt;- lm(s ~ yob + sob, data = df)
first_stage &lt;- lm(s ~ yob + sob + qob, data = df)
anova(no_instrument, first_stage)
# run manual second stage
df &lt;- df %&gt;% mutate(s_hat = predict(first_stage))
second_stage &lt;- lm(lnw ~ s_hat + yob + sob, data = df)
```

---
# Use Built in 2SLS Packages


```r
library(AER)
no_iv_reg &lt;- lm(lnw ~ s, data = df)
no_iv_reg_full &lt;- lm(lnw ~ s + yob + sob, data = df)
iv_q4_reg &lt;- ivreg(lnw ~ yob + s | . - s + q4, data = df)
iv_q4_reg_full &lt;- ivreg(lnw ~ yob + sob + s | . - s + q4, data = df)
iv_allQ_reg &lt;- ivreg(lnw ~ yob + sob + s | . - s + qob, data = df)
```


---
# Outputting Regression Results


```r
library(stargazer)
a &lt;- capture.output(
  stargazer(no_iv_reg, no_iv_reg_full, second_stage, 
            iv_q4_reg, iv_q4_reg_full, iv_allQ_reg,
            type = "text", # no.space = T,
            out = "ak91_iv_regs.txt",
            omit = c("sob", "yob"),
            # omit.labels = c("sob", "yob"),
            omit.stat = c("F", "ser"),
            add.lines = list(c("State Fixed Effects?",
                               "No", "Yes", "Yes", 
                               "No", "Yes", "Yes"),
                             c("Instrument", 
                               "None", "QOB", "QOB",
                               "Q4", "Q4", "QOB")))
)
```


---
# Various Types of Instruments

[todo, add many more]

- natural experiments
- policy variation
- policy/implementation details
- actions taken by third parties

---
# Various Types of Instruments

[todo, add many more]

"good instruments come from a combination of institutional knowledge and ideas about the processes determining the variables of interest" (Angrist &amp; Pischke)

- examples of and papers using different types 
- some ML work to search for instruments

???
Basically, it's not just about data


---
# Is an IV magic?

We can never "prove" that an IV is valid, it has to be argued

In general, causality comes from meaningful variation
- an IV may have meaningful variation for a small population
- realize that casual effects are usually heterogeneous for different groups

--
- IV only gets us a *"Local Average Treatment Effect"*
  - internal vs external (causal) validity?
  - hypothetical

---
# LATE Example

Imagine we randomly offer 50% of students a job training program.
- this group is the "intention to treat" (ITT) group
- only 75% of students accept the Job Training

What do we have?

??
We can do a random experiment measuring the ITT effect.
We could also use the ITT as an instrument for Job Training.

Intuitively though, the ITT would only measure those who chose to accept.

--
{"compliers", "always takers"}

- *does this matter if treatment effects are constant?*

---
# More on Compliers

Avg Effect of Training = 
Effect on Always Takers + 
Effect on Compliers

- usually, the effect of compliers contains the causal effect
- the effect on always takers contains unobserved confounding

---
# Example of ITT vs Causal Treatment Effect

![iv_itt_effects](./assets/iv_rct_itt_effects_regression.png)

???
On the left is the average Training effect.
It's quite high, because it includes people with unobserved motivation/ambition. Even without the offer of Training, they would've sought out Training anyways.

In the middle is the ITT effect, it's lowered because some people never take.

On the right is the 2SLS, IV estimate of the causal effect of Training. It only captures those who were convinced by the instrument (offer) to join Training.

---
# More on LATE

- estimates the avg causal effect for those who are affected by instrument
- must assume that those affected by instrument are affected in the same direction
- *we're skipping the math on instruments, involves the error term*

"IV solves the problem of causal inference in a randomized trial with partial compliance" (Angrist, Pischke)

---
# LATE w/ Potential Outcomes Notation

[todo, optional?]

---
# Characterizing Instruments

- it's also useful to consider some numbers around LATE
  - how many "compliers"/"affected" do we have?
  - what % of our observed treated were affected by `\(IV\)`/$z$?

![iv_size_of_compliers](./assets/iv_size_of_compliers.png)

- small group of "compliers"" is not necessarily bad (like only those on the margin of usefulness)

- (optional) also can compare composition of descriptive variables of the compliers to others.

--- 
# Lots more Details on IV

- see book and reading for additional (multiple instruments, interpretation and math of instruments with covariates, IVs for continuous treatment variables)
- key overall idea: look for things in the world/nature/policies that results in some random variation! Finding that is the most difficult part. Once you find it, you can refer to math and textbooks and references to nail the correct interpretation/identification.

- "key source of variation"
- "what's your identification (strategy)"
- be excited but cautious though, there are a lot of ways things can go wrong
  - different functional forms for the instrument

- overall key advice: always be cautious and recognizing the assumptions that go into causal work. Valuable exercise to think through skeptically.

---
# Weak IV?

Kelibergen-Paap rk Wald F Stat

---
# Sources

- Cameron &amp; Triveti textbook
- Mostly Harmless Econometrics
- Osea Giuntella, slides
    </textarea>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('showSlide', function (slide) {setTimeout(function() {window.dispatchEvent(new Event('resize'));}, 100)});</script>

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
  }
});
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
