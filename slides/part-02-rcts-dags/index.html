<!DOCTYPE html>
<html>
  <head>
    <title>Randomized Control Trials</title>
    <meta charset="utf-8">
    <meta name="author" content="Mathew Kiang, Zhe Zhang, Monica Alexander" />
    <meta name="date" content="2017-03-15" />
    <link rel="stylesheet" href="custom.css" type="text/css" />
    <link rel="stylesheet" href="../custom.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Randomized Control Trials
## Evaluating causality in an <em>ideal</em> setting
### Mathew Kiang, Zhe Zhang, Monica Alexander
### March 15, 2017

---



&lt;!--
class: center, middle


.center[&lt;img src="./assets/do_you_like_dags.jpg"&gt;]
--&gt;

# Roadmap

???

So we've got some of the basic definitions down. We know what a causal effect is and we have a framework for estimating causal effects under certain assumptions. Now we're going to talk about sort of the best case scenario for estimaing causal effects â€” RCTs. **NEXT SLIDE**

While you probably won't ever get to do an RCT in the real world, they are useful to think about because ultimately ever method for causal inference is trying to mimic an RCT and we want to know why. **NEXT SLIDE**

Then we'll take a bit of a detour and talk about DAGs. I think they're very useful; however, a lot of people don't. Regardless, you should know about them because you'll likely come across them in the literature. **NEXT SLIDE**

Finally, we'll return to RCTs and use DAGs to loosen up some of the restrictions of RCTs and show how bias can affect estimates when we don't have an RCT. Then next lecture, Zhe will talk more about the math behind these different biases.

--

### Randomized Control Trials

- Thinking about causality in the ideal setting
--

### Causal Directed Acyclic Graphs (DAGs)

- Useful ways of encoding our beliefs and assumptions

- Helpful for thinking about ways our assumptions can be wrong
--

### Use DAGs to show how RCTs avoid bias

- More about these biases next lecture


---
# Randomized Control Trials

.pull-right[&lt;img src="./assets/james_lind.jpg" width="250"&gt;]

???

Again, we'll start off with a bit of motivation. This is James Lind. He was a Scottish physician in the Royal Navy **NEXT SLIDE**

He conducted the first recorded RCT on scurvy, which is a disease from Vitamin C deficiency and causes pretty bad symptoms. It's a disease of the connective tissue because Vitamin C is required to create connective tissue, all sorts of bad things happen. Severe bleeding, gum disease, inability to heal from superficial wounds, etc. People eventually get personality changes and then die of infection or bleeding. That said, it's very easy to treat. Just some Vitamin C and improvement occurs in days and full recovery in about a month. Was very common back when there were long sea voyages and they were unable to keep fresh fruit available. **NEXT SLIDE**

So Lind was on a ship and he found 12 sailrs with survey. Randomly split them up into 6 groups and gave each group a different treatment in addition to their regular diet. **NEXT SLIDE**

As he suspected, only the group that had citrus fruits showed substantial improvement with one returning back to work and one on the mend (they ran out of fruit before he could completely heal).

--
.footnote[Wikipedia]

- First recorded RCT was done in 1747 by James Lind

--

- Scurvy is a terrible disease caused by Vitamin C deficiency and was a huge issue during long sea voyages

--

- Lind took 12 sailors with scurvy and split them into six groups of two:

    - Groups were assigned: (1) 1 qt cider, (2) 25 drops of vitriol, (3) 6 spoonfuls of vinegar, (4) 1/2 pt of sea water, (5) garlic, mustard, and barley water, (6) 2 oranges and 1 lemon

--

- Only Group 6 (citrus fruit) showed substantial improvement

---
# Randomized Control Trials
.footnote[Hernan Epi 201]


### What's the big deal about RCTs?

--

- Even with a very small sample size, Lind was able to show convincing causal effect

--

- RCTs allow us to gain knowledge about causal effects **without knowing the mechanism** 

    - Lind believed acid stopped putrefaction. 
    - Medicine had not yet understood importance of vitamins.
    
---
# Randomized Control Trials

### But RCTs aren't perfect

- Not every question can be answered with an RCT (feasibility or ethical concerns)

- Smaller sample size often means limited generalizability

---
# RCT Definitions

.footnote[Hernan Epi 201]

- **Randomized**: The intervention is assigned randomly

--

- **Control**: There is (at least) one well-defined comparison group

--

- **Experiment**: Investigators (directly) control the intervention

- **Trial**: An experiment where the goal is to study effect of some medical intervention on humans

    - Trials have ethical requirements that experiments may not (e.g., equipoise)

--
&lt;br&gt;
### In an ideal RCT, there is no loss to follow-up, perfect compliance, only one version of treatment, double (or triple) blind assignment
---
# Randomized Control Trials

- Recall from last lecture, because of the *Fundamental Problem of Causal Inference*, we can never observe both counterfactuals.

--

- Instead, we ask: under what conditions do the data we have properly estimate the data we want? `$$Pr(Y^{a=1})-Pr(Y^{a=0})=Pr(Y|A=1)-Pr(Y|A=0)$$`
--

- Again, recall our assumptions for the Rubin causal model:
--

    - How do we ensure our groups *exchangeable*?
    - That we have *positivity*?
    - And that we have *stability*?

--
### .center[These are all met in an ideal RCT]

---
# Randomized Control Trials

.footnote[Hernan Epi 201]

- Suppose we have a large (nearly infinite) population of perfect compliers

--

- We divide them into two groups: (1) Group Heads and (2) Group Tails 

--

- We assigned the groups by flipping a (fair) coin

--

- Now, we decide to treat Group Heads and not treat Group Tails 

    - The risk of death in Group Heads is: `\(Pr[Y=1|A=1] = .25\)`

--

- Pretend that instead of doing this, we treated Group Tails and did not treat Group Heads. What would the expected risk of death in Group Tails be?

--

    - Still `\(.25\)`

---
class: center, middle
# Exchangeability is a consequence of randomization

--

## Unfortunately, we (usually) won't get to randomize

---
# Formal definition of exchangeability
.footnote[Hernan Epi 201]

The counterfactual outcome `\(Y^a\)` is independent of the actual treatment `\(A\)`.

`$$Y^a \perp A \text{ for all } a$$`

--

- Exchangeability is "another causal concept that cannot be represented by associational (statistical) language"

--

### NOTE!

Exchanagebility is not the same as independence. That is, `$$Y^a \perp A \neq Y \perp A$$`

---
# Aside: Measures of causal effect

If exchangeability holds, we can express the causal effects in different ways:

--

1. **Absolute difference**: `\(ATE = Pr[Y=1|A=1] - Pr[Y=1|A=0]\)`

--

1. **Risk ratio**: `\(ATE = \frac{Pr[Y=1|A=1]}{Pr[Y=1|A=0]}\)`

--

1. **Odds ratio**: `\(ATE = \frac{Pr[Y=1|A=1] / Pr[Y=0|A=1]}{Pr[Y=1|A=0] / Pr[Y=1|A=0]}\)`

---
class: center, middle, inverse
# The Life-changing Magic of DAGs

---
# Causal Directed Acyclic Graphs (DAGs)

.center[&lt;img src="./assets/basic_dag.jpg" width="200"&gt;]

- Graphically, the goal is to estimate magnitude and direction arrow. Statistically, we can only estimate the magnitude

- The edge itself can exist for at least 5 reasons:
    1. Just random luck
    1. `\(X\)` really does cause `\(Y\)` (causal)
    1. `\(Y\)` actually causes `\(X\)` (reverse causation)
    1. `\(X\)` and `\(Y\)` share a common cause (confounding)
    1. `\(X\)` and `\(Y\)` have a common effect that we are conditioning on (selection)
    
- Our job is to figure out which of these reasons is most consistent with the data and rule out all other explanations

.footnote[.red[*]Ch 16 by Maria Glymour in Methods Social Epidemiology]
    
---
# Rules for drawing a DAG

.center[&lt;img src="./assets/example_dag.jpg" width="200"&gt;]

- Time flows left to right (thus arrows always point right)

- An arrow implies our belief that something is *causal*

- The lack of an arrow implies our belief that things are *not* causal

- Everything we are concerned with exists in the DAG

.footnote[.red[*]Ch 16 by Maria Glymour in Methods Social Epidemiology]

---
# Reading DAGs: Causal assumptions

.center[&lt;img src="./assets/example_dag.jpg" width="200"&gt;]

- `\(X\)` and `\(U\)` are direct causes of `\(Y\)`
- `\(Y\)` is a direct cause of `\(Z\)`
- `\(X\)` and `\(U\)` are *not* direct causes of `\(Z\)`, but *indirect* causes through `\(Y\)`
- `\(X\)` and `\(U\)` are not causes of each other
- No two variables share a common cause

.footnote[.red[*]Ch 16 by Maria Glymour in Methods Social Epidemiology]

---
# Reading DAGs: Statistical implications

.center[&lt;img src="./assets/example_dag.jpg" width="200"&gt;]

- Edge implies statistical dependence
- No statistical dependence if there is a *collider*. Two arrow heads into one variable (e.g., `\(U \rightarrow Y \leftarrow X\)`)
- No statistical dependence if we *condition* or *block* a variable (denoted with a box around that variable) or a *descendent* of that variable
- There is statistical dependence if we block a collider or a descendent of that collider

.footnote[.red[*]Ch 16 by Maria Glymour in Methods Social Epidemiology]


---
# Reading DAGs: Statistical implications
.footnote[.red[*]Ch 16 by Maria Glymour in Methods Social Epidemiology]

.center[&lt;img src="./assets/example_dag.jpg" width="200"&gt;]

- `\(X\)` and `\(Y\)` are statistically dependent
- `\(U\)` and `\(Y\)` are statistically dependent
- `\(Y\)` and `\(Z\)` are statistically dependent
--

- `\(X\)` and `\(Z\)` are statistically dependent (i.e., `\(X \rightarrow Y \rightarrow Z\)`)
- `\(U\)` and `\(Z\)` are statistically dependent (i.e., `\(U \rightarrow Y \rightarrow Z\)`)

---
# Reading DAGs: Statistical implications
.footnote[.red[*]Ch 16 by Maria Glymour in Methods Social Epidemiology]

.center[&lt;img src="./assets/example_dag.jpg" width="200"&gt;]

- `\(X\)` and `\(U\)` are statistically independent (blocked by a collider `\(Y\)`)

--
- `\(X\)` and `\(U\)` are statistically dependent, conditional on `\(Y\)` (conditioning on a collider, unblocks that path)

--
- `\(X\)` and `\(U\)` are statistically dependent, conditional on `\(Z\)` (conditioning on a collider's descendent, unblocks that path)

--
- `\(X\)` and `\(Z\)` are statistically independent, conditional on `\(Y\)` (conditioning on `\(Y\)` blocks the `\(X \rightarrow Y \rightarrow Z\)` path)

--
- Similar to above, `\(U\)` and `\(Z\)` are statistically independent, conditional on `\(Y\)`.

---
# DAGs Assumptions
.footnote[.red[*]Ch 16 by Maria Glymour in Methods Social Epidemiology]

.center[&lt;img src="./assets/example_dag.jpg" width="200"&gt;]

1. **Causal Markov Assumption.** Any variable `\(X\)` is independent of any other variable `\(Y\)` conditional on on the direct causes of `\(X\)` (unless `\(Y\)` is an effect of `\(X\)`).
1. **Faithfulness.** Positive and negative causal effects never *perfectly* offset. 
1. **Neglible randomness.** Statistical associations (or lack of such associations) are never due to random change (i.e., large sample size assumption).

---
# DAGs Conclusion
.center[&lt;img src="./assets/example_dag.jpg" width="200"&gt;]

### Powerful way of elucidating our beliefs and assumptions with only a few nodes and edges



---
class: center, middle
# Thanks!

---
# Sources

- [Chapter 16 Methods in Social Epidemiology](http://publicifsv.sund.ku.dk/~nk/epiF14/Glymour_DAGs.pdf) by Maria Glymour


---
# Additional Reading
- TODO
    </textarea>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('showSlide', function (slide) {setTimeout(function() {window.dispatchEvent(new Event('resize'));}, 100)});</script>

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
  }
});
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
